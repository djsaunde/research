Title,Read,Author(s),Year,Synposis
Unsupervised learning of digit recognition using spike-timing-dependent plasticity,Spring 2017,"Peter U. Diehl, Matthew Cook",2015,"A spiking neural network model is described and used to classify the MNIST handwritten digits. Spike-timing-dependent plasticity is used to update synapse weights, inhibition is used to create competition between neurons filtering the input, and an adaptive, homeostatic mechanism is used to adjust sensitivity to different input intensities."
Biologicially inspired load balancing mechanism in neocortical competitive learning,Spring 2018,"Amir Tal, Noam Peled, Hava Siegelmann",2014,"The authors present a simulation of a population of 1000 LIF neurons with layer 5 Martinotti cells (MC) with delayed self-inhibition and layer 5 large basket cell with local Mexican hat-shaped inhibition, as well as STDP learning of the synapses which are connected with distance-dependent randomness between neurons. Input to the network are random bit vectors. The results show that the network is able to organize into a few large (or many small and overlapping) clusters, which compete between themselves yet synchronize within themselves. Various kinds of cluster analysis are applied to the connectivity and activity of the trained network."
A Model for Real-Time Computation in Generic Neural Microcircuits,Spring 2018,"Wolfgang Maass, Thomas Natschlager, Henry Markram",2003,"Liquid state machines (LSMs) are introduced and are motivated from the point of view of the ""anytime computing"" / ""real-time computing"" paradigms inspired by neural computation. In particular, a simulation of a small network of heterogeneous LIF neurons are used to ""filter"" input signals u(t) into a liquid state x(t), and a small set of linear read-out filters are optimized to output a target time series y(t). A non-Turing (that is, continuous in time and real-valued) theory of computation is developed with the LSM, with the result that a sufficiently large / complex ""found"" or ""evolved"" generic circuit will tend to have sufficient computational power for any given real-valued, parallel real-time computing task. An LSM with a small generic neural circuit as the computation reservoir is shown to achieve SOTA results on a dataset of 500 (300 train / 200 test) audio examples of the spoken digits 0-9, with several desirable properties (any-time outputs)."
"Biological Mechanisms for Learning: A Computational Model of Olfactory Learning in the Manduca sexta Moth, with Applications to Neural Nets",Spring 2018,"Charles B. Delahunt, Jeffrey A. Riffell, J. Nathan Kutz",2018,"A model of the insect olfactory system (in particular, the moth) is built using integrate-and-fire neurons is tuned to reproduce experimental in vivo firing rate data. The model is trained to learn new ""odors"" using very few data samples."
"Spiking allows neurons to estimate their causal effect",Spring 2018,"Benjamin James Lansdell, Konrad Paul Kording",2018,Regression discontinuity design (a popular causal technique from economics) is used in a new synaptic learning rule such that neurons may estimate their causal effect on task performance.
Putting a bug in ML: The moth olfactory network learns to read MNIST,Summer 2018,"Charles B. Delahunt, J. Nathan Kutz",2018,"The moth olfactory network model of ""Biological Mechanisms for Learning: A Computational Model..."" is used to classify the MNIST digits using a very small number of samples per digit class (1-20)."