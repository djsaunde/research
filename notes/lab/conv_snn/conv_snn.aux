\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Locally-connected SNNs}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Two-layer convolutional SNNs}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Basic structure}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Schematic diagram of the structure of a two-layer convolutional spiking neural network. For ease of presentation, all data, layers, and weight kernels are depicted as two-dimensional (as in the case of gray-scale image processing). Input data encoded into spike trains is used for the activity of an input layer. Weight kernels are ``slid'' across the input space, multiplied by the input activations, and projected to unique neurons in the corresponding sub-population in the convolutional layer (one per weight kernel). The convolutional layer has inhibitory, recurrent connections, establishing a competition for spiking activity.}}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Recurrent connectivity}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Inhibit all neurons with same receptive field}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Inhibit all other neurons}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Architectural modifications}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Duplicate layer \texttt  {Y} without recurrent connectivity}{2}}
